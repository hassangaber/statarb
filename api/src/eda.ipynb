{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS=['AMT', 'XOM', 'T', 'SO', 'PFE', 'NVDA', 'NFLX', 'JPM', 'JNJ', 'GLD', 'MARK', 'GE', 'COST', 'AMZN', 'TSLA', 'AAPL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the preliminary data analysis to create modelling assumptions, engineer new features, and find out how we can create a target to generate trading signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../../assets/data.csv', index_col=[0])\n",
    "COLS=['DATE','CLOSE','HIGH','VOLUME','VOLATILITY_90D'] # I am only interested in the raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_DATA: dict[str, pd.DataFrame] = {i:data.loc[data.ID==i][COLS] for i in data.ID.unique()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peeking at the data, we see that the features are only available at the end of the trading day; the `HIGH` is only known when you collect all price information, `CLOSE` is the last observation of the day. Similarly, `VOLATILITY_90D` is a rolling calculation of returns so that information is also only known at the end of the trading day.\n",
    "\n",
    "So **Assumption #1** will be that all the trading decisions we make can only be done at the end of the trading day because the raw features we have can only be observed at (daily) market close. The same goes for any engineered features because they are based on the raw features for any calculation. So any trades done on intra-day information will be look-ahead bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_DATA['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = {\n",
    "    \"Inflation_Expectation\": \"TIP\",  # iShares TIPS Bond ETF as a proxy for inflation expectations\n",
    "    \"Unemployment_Proxy\": \"SIVR\",  # Aberdeen Standard Physical Silver Shares ETF (sometimes used as economic health indicator)\n",
    "    \"US_Economy\": \"SPY\",  # SPDR S&P 500 ETF as a proxy for overall US economic health\n",
    "    \"Govt_Debt_Proxy\": \"TLT\",  # iShares 20+ Year Treasury Bond ETF as a proxy for government debt\n",
    "    \"Treasury_10Y\": \"^TNX\",  # 10-Year Treasury Yield\n",
    "    \"Treasury_5Y\": \"^FVX\",  # 5-Year Treasury Yield\n",
    "    \"Treasury_2Y\": \"^IRX\",  # 2-Year Treasury Yield\n",
    "    \"US_Dollar\": \"DX-Y.NYB\",  # US Dollar Index\n",
    "    \"Gold\": \"GC=F\",  # Gold Futures\n",
    "    \"Oil\": \"CL=F\",  # Crude Oil Futures\n",
    "    \"VIX\": \"^VIX\",  # CBOE Volatility Index\n",
    "    \"Real_Estate\": \"IYR\",  # iShares U.S. Real Estate ETF\n",
    "    \"Consumer_Sentiment\": \"XLY\"  # Consumer Discretionary Select Sector SPDR Fund\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = []\n",
    "for indicator, ticker in tickers.items():\n",
    "    try:\n",
    "        data = yf.download(ticker, start=\"2010-01-01\", end=\"2024-08-20\")\n",
    "        if not data.empty:\n",
    "            data.insert(0, \"ID\", indicator)\n",
    "            data=data.drop(['Volume', 'Adj Close'],axis=1)\n",
    "            groups.append(data)\n",
    "        else:\n",
    "            print(f\"No data available for {indicator} ({ticker})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading data for {indicator} ({ticker}): {str(e)}\")\n",
    "\n",
    "macro_data = pd.concat(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = macro_data.loc[macro_data.ID.isin(['Treasury_10Y','Treasury_2Y','Treasury_5Y'])].pivot(columns='ID', values='Close')\n",
    "feature1='Treasury_10Y'\n",
    "feature2='Treasury_2Y'\n",
    "feature3='Treasury_5Y'\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_pivot.index, df_pivot[feature1], label=feature1)\n",
    "plt.plot(df_pivot.index, df_pivot[feature2], label=feature2)\n",
    "plt.plot(df_pivot.index, df_pivot[feature3], label=feature3)\n",
    "\n",
    "plt.title(f\"Yields Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Treasury Bond Yield (%)\")\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_DATA[\"MACRO\"]=macro_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_index = \"^GSPC\"  # S&P 500\n",
    "sector_etfs = {\n",
    "    \"Technology\": \"XLK\",\n",
    "    \"Financial\": \"XLF\",\n",
    "    \"Healthcare\": \"XLV\",\n",
    "    \"Consumer_Discretionary\": \"XLY\",\n",
    "    \"Consumer_Staples\": \"XLP\",\n",
    "    \"Energy\": \"XLE\",\n",
    "    \"Utilities\": \"XLU\",\n",
    "    \"Materials\": \"XLB\",\n",
    "    \"Industrial\": \"XLI\",\n",
    "    \"Real_Estate\": \"XLRE\",\n",
    "    \"Communication_Services\": \"XLC\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_calculate_returns(tickers, start_date, end_date):\n",
    "    data = yf.download(list(tickers.values()) + [market_index], start=start_date, end=end_date)['Adj Close']\n",
    "    returns = data.pct_change().dropna()\n",
    "    return returns\n",
    "\n",
    "def calculate_betas(returns, market_index):\n",
    "    betas = {}\n",
    "    market_returns = returns[market_index]\n",
    "    \n",
    "    for sector, ticker in sector_etfs.items():\n",
    "        sector_returns = returns[ticker]\n",
    "        beta, _, _, _, _ = stats.linregress(market_returns, sector_returns)\n",
    "        betas[sector] = beta\n",
    "    \n",
    "    return pd.Series(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set date range\n",
    "start_date = \"2010-01-01\"\n",
    "end_date = \"2024-08-20\"\n",
    "\n",
    "# Download data and calculate returns\n",
    "returns = download_and_calculate_returns(sector_etfs, start_date, end_date)\n",
    "\n",
    "# Calculate betas\n",
    "sector_betas = calculate_betas(returns, market_index)\n",
    "\n",
    "# Display sector betas\n",
    "print(\"Sector Betas:\")\n",
    "print(sector_betas)\n",
    "\n",
    "# Calculate rolling betas (e.g., 1-year rolling window)\n",
    "window = 252//2  # Approximately 1 trading year\n",
    "rolling_betas = pd.DataFrame(index=returns.index, columns=sector_etfs.keys())\n",
    "\n",
    "for sector, ticker in sector_etfs.items():\n",
    "    rolling_beta = returns[ticker].rolling(window=window).cov(returns[market_index]) / returns[market_index].rolling(window=window).var()\n",
    "    rolling_betas[sector] = rolling_beta\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for sector in sector_etfs.keys():\n",
    "    plt.plot(rolling_betas.index, rolling_betas[sector], label=sector)\n",
    "\n",
    "plt.title(\"Rolling Sector Betas (6-month Window)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Beta\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_DATA[\"STATIC_BETA\"]=sector_betas\n",
    "ID_DATA[\"BETA_6M\"]=rolling_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_DATA.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start='2020-01-01'\n",
    "end='2024-05-03'\n",
    "\n",
    "for k,v in ID_DATA.items():\n",
    "    print(k)\n",
    "    \n",
    "    if type(v) == pd.Series:\n",
    "        continue\n",
    "\n",
    "    print(v.columns.to_list())\n",
    "    \n",
    "    if 'DATE' in v.columns.to_list():\n",
    "        v.DATE=pd.to_datetime(v.DATE)\n",
    "        ID_DATA[k]=v.loc[(v.DATE >= start) & (v.DATE <= end)]\n",
    "\n",
    "    elif 'Date' in v.columns.to_list():\n",
    "        v.Date=pd.to_datetime(v.Date)\n",
    "        ID_DATA[k]=v.loc[(v.Date >= start) & (v.Date <= end)]\n",
    "\n",
    "    else:\n",
    "        print('no date col found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_DATA['MACRO'].reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_DATA['BETA_6M'].reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_beta=ID_DATA['STATIC_BETA']\n",
    "del ID_DATA['STATIC_BETA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=ID_DATA['MACRO']\n",
    "\n",
    "for i in d.ID.unique():\n",
    "    temp=d.loc[d.ID==i].drop(['ID'],axis=1)\n",
    "    ID_DATA[i.upper()]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ID_DATA['MACRO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_master_dataframe(data_dict):\n",
    "    # Define the expected columns\n",
    "    expected_columns = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME', 'VOLATILITY_90D']\n",
    "    \n",
    "    # Create a list to store data for each row\n",
    "    rows = []\n",
    "    \n",
    "    for id, df in data_dict.items():\n",
    "        # Standardize column names\n",
    "        df.columns = df.columns.str.upper()\n",
    "        df = df.rename(columns={\n",
    "            'DATE': 'DATE',\n",
    "            'CLOSE': 'CLOSE',\n",
    "            'HIGH': 'HIGH',\n",
    "            'OPEN': 'OPEN',\n",
    "            'LOW': 'LOW',\n",
    "            'VOLUME': 'VOLUME'\n",
    "        })\n",
    "        \n",
    "        # Ensure 'DATE' is the index\n",
    "        if 'DATE' in df.columns:\n",
    "            df = df.set_index('DATE')\n",
    "        \n",
    "        # For each date in the dataframe\n",
    "        for date, row in df.iterrows():\n",
    "            new_row = {'ID': id, 'DATE': date}\n",
    "            \n",
    "            # Add data for each expected column\n",
    "            for col in expected_columns:\n",
    "                if col in df.columns:\n",
    "                    new_row[col] = row[col]\n",
    "                else:\n",
    "                    new_row[col] = None  # or pd.NA for pandas nullable type\n",
    "            \n",
    "            rows.append(new_row)\n",
    "    \n",
    "    # Create the master dataframe\n",
    "    master_df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Set the column order\n",
    "    column_order = ['ID', 'DATE'] + expected_columns\n",
    "    master_df = master_df[column_order]\n",
    "    \n",
    "    # Set 'DATE' as the index\n",
    "    master_df = master_df.set_index('DATE')\n",
    "    \n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_master_dataframe(ID_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['LOW','OPEN'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.ID=='CONSUMER_SENTIMENT'].HIGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_data=df.loc[df.ID.isin(IDS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VOlUME']=df.VOLUME.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['VOlUME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VOLUME'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sector_betas.index, df.ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_ticker_dict = {\n",
    "    'Technology': ['NVDA', 'AAPL'],\n",
    "    'Financial': ['JPM'],\n",
    "    'Healthcare': ['PFE', 'JNJ'],\n",
    "    'Consumer_Discretionary': ['AMZN', 'TSLA'],\n",
    "    'Consumer_Staples': ['COST'],\n",
    "    'Energy': ['XOM'],\n",
    "    'Utilities': ['SO'],\n",
    "    'Materials': ['GLD'],\n",
    "    'Industrial': ['GE'],\n",
    "    'Real_Estate': ['AMT'],\n",
    "    'Communication_Services': ['T', 'NFLX']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "equity_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.ID=='TREASURY_5Y'].HIGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of macro features to add\n",
    "macro_features = ['INFLATION_EXPECTATION', 'UNEMPLOYMENT_PROXY', 'US_ECONOMY', 'GOVT_DEBT_PROXY', \n",
    "                  'TREASURY_10Y', 'TREASURY_5Y', 'TREASURY_2Y', 'US_DOLLAR', 'GOLD', 'OIL', \n",
    "                  'VIX', 'REAL_ESTATE', 'CONSUMER_SENTIMENT']\n",
    "\n",
    "macro_data = df[df.ID.isin(macro_features)]\n",
    "\n",
    "macro_data=macro_data[['DATE','ID','HIGH']]\n",
    "macro_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_data['DATE'] = pd.to_datetime(equity_data['DATE'])\n",
    "macro_data['DATE'] = pd.to_datetime(macro_data['DATE'])\n",
    "\n",
    "# Reshape macro_data from long to wide format\n",
    "macro_data_wide = macro_data.pivot(index='DATE', columns='ID', values='HIGH')\n",
    "macro_data_wide.columns = ['MACRO_' + col for col in macro_data_wide.columns]  # Prefix macro columns\n",
    "macro_data_wide.columns.name = None  # Remove the name from the columns index\n",
    "\n",
    "# List of macro features (should match the unique IDs in macro_data)\n",
    "macro_features = ['INFLATION_EXPECTATION', 'UNEMPLOYMENT_PROXY', 'US_ECONOMY', 'GOVT_DEBT_PROXY', \n",
    "                  'TREASURY_10Y', 'TREASURY_5Y', 'TREASURY_2Y', 'US_DOLLAR', 'GOLD', 'OIL', \n",
    "                  'VIX', 'REAL_ESTATE', 'CONSUMER_SENTIMENT']\n",
    "\n",
    "# Ensure all expected features are present\n",
    "for feature in macro_features:\n",
    "    if f'MACRO_{feature}' not in macro_data_wide.columns:\n",
    "        print(f\"Warning: {feature} not found in macro data\")\n",
    "\n",
    "# Function to add macro features to a single ID's data\n",
    "def add_macro_features(group):\n",
    "    return pd.merge(group, macro_data_wide, left_on='DATE', right_index=True, how='left')\n",
    "\n",
    "# Apply the function to each ID group\n",
    "equity_data_with_macro = equity_data.groupby('ID', group_keys=False).apply(add_macro_features).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_data_with_macro[equity_data_with_macro.ID=='AAPL'].MACRO_INFLATION_EXPECTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_data_with_macro[equity_data_with_macro.ID=='NVDA'].MACRO_INFLATION_EXPECTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_data_with_macro.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_DATA['BETA_6M'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_data_with_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by ID and shift the data by one day\n",
    "equity_data_with_macro = equity_data_with_macro.groupby('ID').apply(lambda x: x.shift(-1)).reset_index(drop=True)\n",
    "\n",
    "# Remove the last row for each ID (which will be NaN after shifting)\n",
    "equity_data_with_macro = equity_data_with_macro.groupby('ID').apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
    "\n",
    "for sector, tickers in sector_ticker_dict.items():\n",
    "    beta_values = ID_DATA['BETA_6M'][sector.upper()].values\n",
    "    for ticker in tickers:\n",
    "        ticker_mask = equity_data_with_macro['ID'] == ticker\n",
    "        ticker_length = ticker_mask.sum()\n",
    "        \n",
    "        if ticker_length > 0:\n",
    "            # Ensure beta_values matches the length of the ticker data\n",
    "            adjusted_beta_values = np.resize(beta_values, ticker_length)\n",
    "            equity_data_with_macro.loc[ticker_mask, 'BETA_TS'] = adjusted_beta_values\n",
    "        else:\n",
    "            print(f\"No data found for ticker {ticker}\")\n",
    "\n",
    "# Check the result\n",
    "print(equity_data_with_macro[['ID', 'BETA_TS']].head(10))\n",
    "print(equity_data_with_macro['BETA_TS'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_data_with_macro.loc[equity_data_with_macro.ID=='AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_data_with_macro.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equity_data_with_macro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
